#!/bin/bash
#
#                         License
#
# Copyright (C) 2022  David Valin dvalin@redhat.com
#
# This program is free software; you can redistribute it and/or
# modify it under the terms of the GNU General Public License
# as published by the Free Software Foundation; either version 2
# of the License, or (at your option) any later version.
#
# This program is distributed in the hope that it will be useful,
# but WITHOUT ANY WARRANTY; without even the implied warranty of
# MERCHANTABILITY or FITNESS FOR A PARTICULAR PURPOSE.  See the
# GNU General Public License for more details.
#
# You should have received a copy of the GNU General Public License
# along with this program; if not, write to the Free Software
# Foundation, Inc., 51 Franklin Street, Fifth Floor, Boston, MA  02110-1301, USA.
#
# This script automates the execution of coremark_pro.  It will determine the
# set of default run parameters based on the system configuration.
#
coremark_pro_version="v1.1.2743"
commit="none"
test_name_run="coremark_pro"
arguments="$@"

exit_out()
{
	echo $1
	exit $2
}

if [ ! -f "/tmp/${test_name_run}.out" ]; then
	command="${0} $@"
	$command &> /tmp/${test_name_run}.out
	rtc=$?
	cat /tmp/${test_name_run}.out
	rm /tmp/${test_name_run}.out
	exit $rtc
fi

curdir=`pwd`
if [[ $0 == "./"* ]]; then
	chars=`echo $0 | awk -v RS='/' 'END{print NR-1}'`
	if [[ $chars == 1 ]]; then
		run_dir=`pwd`
	else
		run_dir=`echo $0 | cut -d'/' -f 1-${chars} | cut -d'.' -f2-`
		run_dir="${curdir}${run_dir}"
	fi
elif [[ $0 != "/"* ]]; then
	dir=`echo $0 | rev | cut -d'/' -f2- | rev`
	run_dir="${curdir}/${dir}"
else
	chars=`echo $0 | awk -v RS='/' 'END{print NR-1}'`
	run_dir=`echo $0 | cut -d'/' -f 1-${chars}`
	if [[ $run_dir != "/"* ]]; then
		run_dir=${curdir}/${run_dir}
	fi
fi
cd $run_dir

setup_done=0
out_file=""
show_usage=0
cpu_add=0
powers_2=0
no_overrides=0

summary_file="coremark_pro.summary"
rm $summary_file

pull_data()
{
	pro_file=`mktemp /tmp/pro_reduce_data.XXXXX`
	test_name=${1}
	grep "^${test_name}" coremark_pro_run* | cut -d':' -f2 > ${pro_file}
	multicore=0.0
	singlecore=0.0
	scaling=0.0
	iterations=0
	while IFS= read -r line
	do
		let "iterations=$iterations+1"
		value=`echo $line | awk '{print $2}'`
		multicore=`echo "${multicore}+${value}"| bc -l`
		value=`echo $line | awk '{print $3}'`
		singlecore=`echo "${singlecore}+${value}"| bc -l`
		value=`echo $line | awk '{print $4}'`
		scaling=`echo "${scaling}+${value}"| bc -l`
	done < "${pro_file}"
	rm ${pro_file}
	multicore=`echo "${multicore}/${iterations}" | bc -l`
	singlecore=`echo "${singlecore}/${iterations}" | bc -l`
	scaling=`echo "${scaling}/${iterations}" | bc -l`
	printf "%-47s %10.2f %10.2f %10.2f\n" $test_name $multicore $singlecore $scaling >> $summary_file
}

produce_summary_report()
{
	found=0
	while IFS= read -r line
	do
		if [[ $found -eq 1 ]]; then
			if [[ ${line} == "" ]]; then
				echo $line >> $summary_file
				continue
			fi
			if [[ ${line} == "MARK"* ]]; then
				echo $line >> $summary_file
				continue
			fi
			if [[ ${line} == "Mark"* ]]; then
				echo $line >> $summary_file
				continue
			fi
			if [[ ${line} == "-----"* ]]; then
				echo $line >> $summary_file
				continue
			fi
			if [[ ${line} == "CoreMark"* ]]; then
				found=0
			fi
			test_name=`echo $line | awk '{print $1}'`
			pull_data $test_name
			continue
		fi
		if [[ $line == "------"* ]]; then
			found=1
		fi
		echo $line >> $summary_file
	done < "coremark_pro_run_${1}"
}

generate_csv_file()
{
	#
	# Create the csv file.
	#

	echo Test:Multi iterations:Single Iterations:Scaling > results.csv
	items="^cjpeg-rose7-preset ^core ^linear_alg-mid-100x100-sp ^loops-all-mid-10k-sp ^nnet_test ^parser-125k ^radix2-big-64k ^sha-test ^zip-test"
	for i in $items; do
		multi_iter=0.0
		single_iter=0.0
		scaling=0.0
		samples=0
		for j in `ls -d coremark_pro_run_*`; do
			line=`grep $i $j`
			worker=`echo $line | awk '{print $2}'`
			multi_iter=`echo $multi_iter+$worker | bc`
			worker=`echo $line | awk '{print $3}'`
			single_iter=`echo $single_iter+$worker | bc`
			worker=`echo $line | awk '{print $4}'`
			scaling=`echo $scaling+$worker | bc`
			let "samples=$samples+1"
		done
		multi_iter=`echo "scale = 2;$multi_iter / ${samples}.00" | bc -l`
		single_iter=`echo "scale = 2;$single_iter / ${samples}.00" | bc -l`
		scaling=`echo "scale = 2;$scaling / ${samples}.00" | bc -l` 
		name=`echo $i | sed "s/\^//g"`
		echo $name:$multi_iter:$single_iter:$scaling >> results.csv
	done
}

save_results()
{
	rm -rf /tmp/results_${test_name_run}_*
	RESULTSDIR=/tmp/results_${test_name_run}_${to_tuned_setting}_$(date "+%Y.%m.%d-%H.%M.%S")
	mkdir $RESULTSDIR
	mv /tmp/${test_name_run}.out ${RESULTSDIR}
	if [[ $commit == "none" ]]; then
		echo tag: ${coremark_pro_version} > ${RESULTSDIR}/coremark_pro_version
	else
		echo commit: ${commit} > ${RESULTSDIR}/coremark_pro_version
	fi
	cp results.csv $RESULTSDIR
	cp ${curdir}/meta_data.yml ${RESULTSDIR}
	mv $summary_file $RESULTSDIR
	grep -q ":::" results.csv
	if [ $? -eq 0 ]; then
		echo Failed > $RESULTSDIR/test_results_report
	else
		echo Ran > $RESULTSDIR/test_results_report
	fi
	cp coremark_pro_run* $RESULTSDIR
	value=`grep CoreMark-PRO  ${RESULTSDIR}/coremark_pro.summary | head -1`
	value_out=`echo $value | cut -d' ' -f2,3 | sed "s/ /:/g"`
	echo "Score:${value_out}"  >>  $RESULTSDIR/results.csv
	pushd /tmp > /dev/null
	ln -s ${RESULTSDIR} results_${test_name_run}_${to_tuned_setting}
	mv  ${test_name_run}_ ${RESULTSDIR}
	rm -f results_pbench.tar 
	working_dir=`ls -rtd /tmp/results*${test_name_run}* | grep -v tar | tail -1`
	find -L ${working_dir} -type f | tar --transform 's/.*\///g' -cf results_pbench.tar --files-from=/dev/stdin
	tar hcf results_${test_name_run}_${to_tuned_setting}.tar results_${test_name_run}_${to_tuned_setting}
	cp  results_${test_name_run}_${to_tuned_setting}.tar results_pbench_${test_name_run}_${to_tuned_setting}.tar
}

#
# Update cjpeg-rose7-preset
#

update_options()
{
# $1 opt directory
# $2 opt file
# $3 value 1 set to
# $4 value 2 set to

	index=0

	if [[ ! -f ${1}/${2}_old ]]; then
		while IFS= read -r line
		do
			if [[ $line == *"override WLD_CMD_FLAGS"* ]]; then
				if [ $index -eq 0 ]; then
					echo "override WLD_CMD_FLAGS=${3}" >> ${2}_new
					let "index=${index}+1"
				else
					echo "override WLD_CMD_FLAGS=${4}" >> ${2}_new
				fi
				continue
			fi
			echo $line >> ${2}_new
		done < "${1}/${2}"
		mv ${1}/${2} ${1}/${2}_old
		mv ${2}_new ${1}/${2}
	fi
}

update_build_options()
{
	pushd workloads > /dev/null

	update_options cjpeg-rose7-preset cjpeg-rose7-preset.opt "-i2000" "-i50000"
	update_options core core.opt "-i1000" "-i1000"
	update_options linear_alg-mid-100x100-sp linear_alg-mid-100x100-sp.opt "-i3000" "-i100000"
	update_options loops-all-mid-10k-sp loops-all-mid-10k-sp.opt "-i1000" "-i2000"
	update_options nnet_test nnet_test.opt "-i1000" "-i3000"
	update_options parser-125k parser-125k.opt "-i1000" "-i1000"
	update_options radix2-big-64k radix2-big-64k.opt "-i10000" "-i200000"
	update_options sha-test sha-test.opt "-i3000" "-i100000"
	update_options zip-test zip-test.opt "-i2000" "-i40000"

	popd >/dev/null
}

run_coremark_pro()
{
	if [ ! -d coremark-pro ]; then
		if [[ $commit == "none" ]]; then
			GIT_TERMINAL_PROMPT=0 git clone --depth 1 --branch ${coremark_pro_version} https://github.com/eembc/coremark-pro
			if [ $? -ne 0 ]; then
				exit_out "Failed to clone https://github.com/eembc/coremark-pro version ${coremark_pro_version}" 1
			fi
		else
			GIT_TERMINAL_PROMPT=0 git clone https://github.com/eembc/coremark-pro
			if [ $? != 0 ]; then
				exit_out "Failed to clone https://github.com/eembc/coremark-pro" 1
			fi
			pushd coremark-pro > /dev/null
			GIT_TERMINAL_PROMPT=0 git checkout ${commit}
			if [ $? -ne 0 ]; then
				exit_out "Failed to checkout ${commit}" 1
			fi
			popd > /dev/null
		fi
	fi
	pushd coremark-pro > /dev/null

	if [ $to_pbench -eq 0 ]; then
		#
		# Iteration of test.
		#
		if [ $no_overrides -eq 0 ]; then
			update_build_options
		fi
		make TARGET=linux64 build
		numb_cpus=`cat /proc/cpuinfo | grep processor | wc -l`
		for iter in $(seq 1 1 $to_times_to_run); do
			make_flags="TARGET=linux64 XCMD=-c${numb_cpus} certify-all"
			make $make_flags > coremark_pro_run_${iter}
			if [ $? -ne 0 ]; then
				exit_out "make Failed, make $make_flags" 1
			fi
		done

		for iter in $(seq 1 1 $to_times_to_run); do
			produce_summary_report $iter
		done

		generate_csv_file
		save_results
		popd > /dev/null
	else
		popd > /dev/null
		source ~/.bashrc
		cd $curdir
		arguments="${arguments} --test_iterations ${to_times_to_run}"
		echo $TOOLS_BIN/execute_via_pbench --cmd_executing "$0" $arguments --test ${test_name_run} --spacing 11 --pbench_stats $to_pstats
		$TOOLS_BIN/execute_via_pbench --cmd_executing "$0" $arguments --test ${test_name_run} --spacing 11 --pbench_stats $to_pstats
		if [ $? -ne 0 ]; then
			exit_out "Execution via pbench failed\n" 1
		fi
	fi
}

usage()
{
	echo "$1 Usage:"
	echo "  --commit <n>: Commit to use.  If not designated, will use tag ${coremark_pro_version}"
	echo "  --no-overrides: If present we will not tune the make files"
	echo "  --test_iterations n: number of times to run the test."
	source test_tools/general_setup --usage
	exit 0
}

#
# Clone the repo that contains the common code and tools
#

install_tools_git()
{
	give_usage=0
	tools_git=https://github.com/redhat-performance/test_tools-wrappers

	found=0
	for arg in "$@"; do
		if [ $found -eq 1 ]; then
			tools_git=$arg
			found=0
		fi
		if [[ $arg == "--tools_git" ]]; then
			found=1
		fi
	
		#
		# We do the usage check here, as we do not want to be calling
		# the common parsers then checking for usage here.  Doing so will
		# result in the script exiting with out giving the test options.
		#
		if [[ $arg == "--usage" ]]; then
			give_usage=1
		fi
	done

	#
	# Check to see if the test tools directory exists.  If it does, we do not need to
	# clone the repo.
	#
	if [ ! -d "test_tools" ]; then
		GIT_TERMINAL_PROMPT=0 git clone $tools_git test_tools
		if [ $? -ne 0 ]; then
			exit_out "pulling git $tools_git failed." 1
		fi
	fi
	if [ $give_usage -eq 1 ]; then
		usage $0
	fi
}

install_tools_git "$@"
#
# Variables set by general setup.
#
# TOOLS_BIN: points to the tool directory
# to_home_root: home directory
# to_configuration: configuration information
# to_times_to_run: number of times to run the test
# to_pbench: Run the test via pbench
# to_pbench_copy: Copy the data to the pbench repository, not move_it.
# to_puser: User running pbench
# to_run_label: Label for the run
# to_user: User on the test system running the test
# to_sys_type: for results info, basically aws, azure or local
# to_sysname: name of the system
# to_tuned_setting: tuned setting
#

source test_tools/general_setup "$@"

ARGUMENT_LIST=(
	"commit"
	"test_iterations"
)

NO_ARGUMENTS=(
	"no-overrides"
	"usage"
)

# read arguments
opts=$(getopt \
	--longoptions "$(printf "%s:," "${ARGUMENT_LIST[@]}")" \
	--longoptions "$(printf "%s," "${NO_ARGUMENTS[@]}")" \
	--name "$(basename "$0")" \
	--options "h" \
	-- "$@"
)

eval set --$opts

while [[ $# -gt 0 ]]; do
	case "$1" in
		--commit)
			commit=$2
			shift 2
		;;
		--no-overrides)
			no_overrides=1
			shift 1
		;;
		--test_iterations)
			to_times_to_run=$2
			shift 2
		;;
		-h)
			usage $0
		;;
		--)
			break
		;;
		*)
			exit_out "option not found $1" 1
		;;
	esac
done

if [[ -d "coremark-pro" ]]; then
	rm -rf coremark-pro
fi
run_coremark_pro

exit 0
